{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to the workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.47.0 to work with mlw-test\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241464500
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and upload batch data\r\n",
        "Generate a random sample from our diabetes CSV file, upload that data to a datastore in the Azure Machine Learning workspace, and register a dataset for it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore, Dataset\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "# Set default data store\r\n",
        "ws.set_default_datastore('workspaceblobstore')\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Enumerate all datastores, indicating which is the default\r\n",
        "for ds_name in ws.datastores:\r\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\r\n",
        "\r\n",
        "# Load the diabetes data\r\n",
        "diabetes = pd.read_csv('../../data/diabetes/diabetes.csv')\r\n",
        "\r\n",
        "# Get a 100-item sample of the feature columns (not the diabetic label)\r\n",
        "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\r\n",
        "\r\n",
        "# Create a folder\r\n",
        "batch_folder = './diabetes-batch-data'\r\n",
        "os.makedirs(batch_folder, exist_ok=True)\r\n",
        "print(\"Folder created!\")\r\n",
        "\r\n",
        "# Save each sample as a separate file\r\n",
        "print(\"Saving files...\")\r\n",
        "for i in range(100):\r\n",
        "    fname = str(i+1) + '.csv'\r\n",
        "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\r\n",
        "print(\"files saved!\")\r\n",
        "\r\n",
        "# Upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "default_ds.upload(src_dir=\"diabetes-batch-data\", target_path=\"diabetes-batch-data\", overwrite=True, show_progress=True)\r\n",
        "\r\n",
        "# Register a dataset for the input data\r\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-batch-data/'), validate=False)\r\n",
        "try:\r\n",
        "    batch_data_set = batch_data_set.register(workspace=ws, \r\n",
        "                                             name='diabetes-batch-data',\r\n",
        "                                             description='Diabetes batch data',\r\n",
        "                                             create_new_version=True)\r\n",
        "except Exception as ex:\r\n",
        "    print(ex)\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workspaceworkingdirectory - Default = False\nworkspaceartifactstore - Default = False\nworkspacefilestore - Default = False\nworkspaceblobstore - Default = True\nFolder created!\nSaving files...\nfiles saved!\nUploading files to datastore...\nUploading an estimated of 102 files\nUploading diabetes-batch-data/.amlignore\nUploaded diabetes-batch-data/.amlignore, 1 files out of an estimated total of 102\nUploading diabetes-batch-data/.amlignore.amltmp\nUploaded diabetes-batch-data/.amlignore.amltmp, 2 files out of an estimated total of 102\nUploading diabetes-batch-data/1.csv\nUploaded diabetes-batch-data/1.csv, 3 files out of an estimated total of 102\nUploading diabetes-batch-data/10.csv\nUploaded diabetes-batch-data/10.csv, 4 files out of an estimated total of 102\nUploading diabetes-batch-data/100.csv\nUploaded diabetes-batch-data/100.csv, 5 files out of an estimated total of 102\nUploading diabetes-batch-data/11.csv\nUploaded diabetes-batch-data/11.csv, 6 files out of an estimated total of 102\nUploading diabetes-batch-data/12.csv\nUploaded diabetes-batch-data/12.csv, 7 files out of an estimated total of 102\nUploading diabetes-batch-data/13.csv\nUploaded diabetes-batch-data/13.csv, 8 files out of an estimated total of 102\nUploading diabetes-batch-data/14.csv\nUploaded diabetes-batch-data/14.csv, 9 files out of an estimated total of 102\nUploading diabetes-batch-data/15.csv\nUploaded diabetes-batch-data/15.csv, 10 files out of an estimated total of 102\nUploading diabetes-batch-data/16.csv\nUploaded diabetes-batch-data/16.csv, 11 files out of an estimated total of 102\nUploading diabetes-batch-data/17.csv\nUploaded diabetes-batch-data/17.csv, 12 files out of an estimated total of 102\nUploading diabetes-batch-data/18.csv\nUploaded diabetes-batch-data/18.csv, 13 files out of an estimated total of 102\nUploading diabetes-batch-data/19.csv\nUploaded diabetes-batch-data/19.csv, 14 files out of an estimated total of 102\nUploading diabetes-batch-data/2.csv\nUploaded diabetes-batch-data/2.csv, 15 files out of an estimated total of 102\nUploading diabetes-batch-data/20.csv\nUploaded diabetes-batch-data/20.csv, 16 files out of an estimated total of 102\nUploading diabetes-batch-data/21.csv\nUploaded diabetes-batch-data/21.csv, 17 files out of an estimated total of 102\nUploading diabetes-batch-data/22.csv\nUploaded diabetes-batch-data/22.csv, 18 files out of an estimated total of 102\nUploading diabetes-batch-data/23.csv\nUploaded diabetes-batch-data/23.csv, 19 files out of an estimated total of 102\nUploading diabetes-batch-data/24.csv\nUploaded diabetes-batch-data/24.csv, 20 files out of an estimated total of 102\nUploading diabetes-batch-data/25.csv\nUploaded diabetes-batch-data/25.csv, 21 files out of an estimated total of 102\nUploading diabetes-batch-data/26.csv\nUploaded diabetes-batch-data/26.csv, 22 files out of an estimated total of 102\nUploading diabetes-batch-data/27.csv\nUploaded diabetes-batch-data/27.csv, 23 files out of an estimated total of 102\nUploading diabetes-batch-data/28.csv\nUploaded diabetes-batch-data/28.csv, 24 files out of an estimated total of 102\nUploading diabetes-batch-data/29.csv\nUploaded diabetes-batch-data/29.csv, 25 files out of an estimated total of 102\nUploading diabetes-batch-data/3.csv\nUploaded diabetes-batch-data/3.csv, 26 files out of an estimated total of 102\nUploading diabetes-batch-data/30.csv\nUploaded diabetes-batch-data/30.csv, 27 files out of an estimated total of 102\nUploading diabetes-batch-data/31.csv\nUploaded diabetes-batch-data/31.csv, 28 files out of an estimated total of 102\nUploading diabetes-batch-data/32.csv\nUploaded diabetes-batch-data/32.csv, 29 files out of an estimated total of 102\nUploading diabetes-batch-data/33.csv\nUploaded diabetes-batch-data/33.csv, 30 files out of an estimated total of 102\nUploading diabetes-batch-data/34.csv\nUploaded diabetes-batch-data/34.csv, 31 files out of an estimated total of 102\nUploading diabetes-batch-data/35.csv\nUploaded diabetes-batch-data/35.csv, 32 files out of an estimated total of 102\nUploading diabetes-batch-data/36.csv\nUploaded diabetes-batch-data/36.csv, 33 files out of an estimated total of 102\nUploading diabetes-batch-data/37.csv\nUploaded diabetes-batch-data/37.csv, 34 files out of an estimated total of 102\nUploading diabetes-batch-data/38.csv\nUploaded diabetes-batch-data/38.csv, 35 files out of an estimated total of 102\nUploading diabetes-batch-data/39.csv\nUploaded diabetes-batch-data/39.csv, 36 files out of an estimated total of 102\nUploading diabetes-batch-data/4.csv\nUploaded diabetes-batch-data/4.csv, 37 files out of an estimated total of 102\nUploading diabetes-batch-data/40.csv\nUploaded diabetes-batch-data/40.csv, 38 files out of an estimated total of 102\nUploading diabetes-batch-data/41.csv\nUploaded diabetes-batch-data/41.csv, 39 files out of an estimated total of 102\nUploading diabetes-batch-data/42.csv\nUploaded diabetes-batch-data/42.csv, 40 files out of an estimated total of 102\nUploading diabetes-batch-data/43.csv\nUploaded diabetes-batch-data/43.csv, 41 files out of an estimated total of 102\nUploading diabetes-batch-data/44.csv\nUploaded diabetes-batch-data/44.csv, 42 files out of an estimated total of 102\nUploading diabetes-batch-data/45.csv\nUploaded diabetes-batch-data/45.csv, 43 files out of an estimated total of 102\nUploading diabetes-batch-data/46.csv\nUploaded diabetes-batch-data/46.csv, 44 files out of an estimated total of 102\nUploading diabetes-batch-data/47.csv\nUploaded diabetes-batch-data/47.csv, 45 files out of an estimated total of 102\nUploading diabetes-batch-data/48.csv\nUploaded diabetes-batch-data/48.csv, 46 files out of an estimated total of 102\nUploading diabetes-batch-data/49.csv\nUploaded diabetes-batch-data/49.csv, 47 files out of an estimated total of 102\nUploading diabetes-batch-data/5.csv\nUploaded diabetes-batch-data/5.csv, 48 files out of an estimated total of 102\nUploading diabetes-batch-data/50.csv\nUploaded diabetes-batch-data/50.csv, 49 files out of an estimated total of 102\nUploading diabetes-batch-data/51.csv\nUploaded diabetes-batch-data/51.csv, 50 files out of an estimated total of 102\nUploading diabetes-batch-data/52.csv\nUploaded diabetes-batch-data/52.csv, 51 files out of an estimated total of 102\nUploading diabetes-batch-data/53.csv\nUploaded diabetes-batch-data/53.csv, 52 files out of an estimated total of 102\nUploading diabetes-batch-data/54.csv\nUploaded diabetes-batch-data/54.csv, 53 files out of an estimated total of 102\nUploading diabetes-batch-data/55.csv\nUploaded diabetes-batch-data/55.csv, 54 files out of an estimated total of 102\nUploading diabetes-batch-data/56.csv\nUploaded diabetes-batch-data/56.csv, 55 files out of an estimated total of 102\nUploading diabetes-batch-data/57.csv\nUploaded diabetes-batch-data/57.csv, 56 files out of an estimated total of 102\nUploading diabetes-batch-data/58.csv\nUploaded diabetes-batch-data/58.csv, 57 files out of an estimated total of 102\nUploading diabetes-batch-data/59.csv\nUploaded diabetes-batch-data/59.csv, 58 files out of an estimated total of 102\nUploading diabetes-batch-data/6.csv\nUploaded diabetes-batch-data/6.csv, 59 files out of an estimated total of 102\nUploading diabetes-batch-data/60.csv\nUploaded diabetes-batch-data/60.csv, 60 files out of an estimated total of 102\nUploading diabetes-batch-data/61.csv\nUploaded diabetes-batch-data/61.csv, 61 files out of an estimated total of 102\nUploading diabetes-batch-data/62.csv\nUploaded diabetes-batch-data/62.csv, 62 files out of an estimated total of 102\nUploading diabetes-batch-data/63.csv\nUploaded diabetes-batch-data/63.csv, 63 files out of an estimated total of 102\nUploading diabetes-batch-data/64.csv\nUploaded diabetes-batch-data/64.csv, 64 files out of an estimated total of 102\nUploading diabetes-batch-data/65.csv\nUploaded diabetes-batch-data/65.csv, 65 files out of an estimated total of 102\nUploading diabetes-batch-data/66.csv\nUploaded diabetes-batch-data/66.csv, 66 files out of an estimated total of 102\nUploading diabetes-batch-data/67.csv\nUploaded diabetes-batch-data/67.csv, 67 files out of an estimated total of 102\nUploading diabetes-batch-data/68.csv\nUploaded diabetes-batch-data/68.csv, 68 files out of an estimated total of 102\nUploading diabetes-batch-data/69.csv\nUploaded diabetes-batch-data/69.csv, 69 files out of an estimated total of 102\nUploading diabetes-batch-data/7.csv\nUploaded diabetes-batch-data/7.csv, 70 files out of an estimated total of 102\nUploading diabetes-batch-data/70.csv\nUploaded diabetes-batch-data/70.csv, 71 files out of an estimated total of 102\nUploading diabetes-batch-data/71.csv\nUploaded diabetes-batch-data/71.csv, 72 files out of an estimated total of 102\nUploading diabetes-batch-data/72.csv\nUploaded diabetes-batch-data/72.csv, 73 files out of an estimated total of 102\nUploading diabetes-batch-data/73.csv\nUploaded diabetes-batch-data/73.csv, 74 files out of an estimated total of 102\nUploading diabetes-batch-data/74.csv\nUploaded diabetes-batch-data/74.csv, 75 files out of an estimated total of 102\nUploading diabetes-batch-data/75.csv\nUploaded diabetes-batch-data/75.csv, 76 files out of an estimated total of 102\nUploading diabetes-batch-data/76.csv\nUploaded diabetes-batch-data/76.csv, 77 files out of an estimated total of 102\nUploading diabetes-batch-data/77.csv\nUploaded diabetes-batch-data/77.csv, 78 files out of an estimated total of 102\nUploading diabetes-batch-data/78.csv\nUploaded diabetes-batch-data/78.csv, 79 files out of an estimated total of 102\nUploading diabetes-batch-data/79.csv\nUploaded diabetes-batch-data/79.csv, 80 files out of an estimated total of 102\nUploading diabetes-batch-data/8.csv\nUploaded diabetes-batch-data/8.csv, 81 files out of an estimated total of 102\nUploading diabetes-batch-data/80.csv\nUploaded diabetes-batch-data/80.csv, 82 files out of an estimated total of 102\nUploading diabetes-batch-data/81.csv\nUploaded diabetes-batch-data/81.csv, 83 files out of an estimated total of 102\nUploading diabetes-batch-data/82.csv\nUploaded diabetes-batch-data/82.csv, 84 files out of an estimated total of 102\nUploading diabetes-batch-data/83.csv\nUploaded diabetes-batch-data/83.csv, 85 files out of an estimated total of 102\nUploading diabetes-batch-data/84.csv\nUploaded diabetes-batch-data/84.csv, 86 files out of an estimated total of 102\nUploading diabetes-batch-data/86.csv\nUploaded diabetes-batch-data/86.csv, 87 files out of an estimated total of 102\nUploading diabetes-batch-data/87.csv\nUploaded diabetes-batch-data/87.csv, 88 files out of an estimated total of 102\nUploading diabetes-batch-data/88.csv\nUploaded diabetes-batch-data/88.csv, 89 files out of an estimated total of 102\nUploading diabetes-batch-data/89.csv\nUploaded diabetes-batch-data/89.csv, 90 files out of an estimated total of 102\nUploading diabetes-batch-data/9.csv\nUploaded diabetes-batch-data/9.csv, 91 files out of an estimated total of 102\nUploading diabetes-batch-data/90.csv\nUploaded diabetes-batch-data/90.csv, 92 files out of an estimated total of 102\nUploading diabetes-batch-data/91.csv\nUploaded diabetes-batch-data/91.csv, 93 files out of an estimated total of 102\nUploading diabetes-batch-data/92.csv\nUploaded diabetes-batch-data/92.csv, 94 files out of an estimated total of 102\nUploading diabetes-batch-data/85.csv\nUploaded diabetes-batch-data/85.csv, 95 files out of an estimated total of 102\nUploading diabetes-batch-data/93.csv\nUploaded diabetes-batch-data/93.csv, 96 files out of an estimated total of 102\nUploading diabetes-batch-data/94.csv\nUploaded diabetes-batch-data/94.csv, 97 files out of an estimated total of 102\nUploading diabetes-batch-data/95.csv\nUploaded diabetes-batch-data/95.csv, 98 files out of an estimated total of 102\nUploading diabetes-batch-data/96.csv\nUploaded diabetes-batch-data/96.csv, 99 files out of an estimated total of 102\nUploading diabetes-batch-data/97.csv\nUploaded diabetes-batch-data/97.csv, 100 files out of an estimated total of 102\nUploading diabetes-batch-data/98.csv\nUploaded diabetes-batch-data/98.csv, 101 files out of an estimated total of 102\nUploading diabetes-batch-data/99.csv\nUploaded diabetes-batch-data/99.csv, 102 files out of an estimated total of 102\nUploaded 102 files\nDone!\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241476813
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's take a look at models registered in the workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes-model version: 7\n\t Algorithm : Decision Tree Classifier\n\t Training context : Pipeline\n\t AUC : 0.8832546157718848\n\t Accuracy : 0.898\n\n\ndiabetes-model version: 6\n\t Algorithm : Logistic Regression\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 5\n\t Algorithm : Decision Tree Classifier\n\t Training context : Pipeline\n\t AUC : 0.88375696004516\n\t Accuracy : 0.8986666666666666\n\n\ndiabetes-model version: 4\n\t Algorithm : Logistic Regression\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 3\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 2\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 1\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes_model version: 10\n\t Training context : File dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\nnyc-taxi-fare version: 1\n\t Type : GradientBoostingRegressor\n\t Run ID : a467b104-6d83-492e-8b51-e27ef3274918\n\t Metrics : {'rmse': 4.201611563528527, 'mae': 2.1113181246358903, 'R2 score': 0.8145380981078642}\n\n\ndiabetes_model version: 9\n\t Training context : Inline Training\n\t AUC : 0.8753520075625654\n\t Accuracy : 0.888\n\n\ndiabetes_model version: 8\n\t Training context : Pipeline\n\t AUC : 0.881942902191734\n\t Accuracy : 0.8975555555555556\n\n\ndiabetes_model version: 7\n\t Training context : Pipeline\n\t AUC : 0.8827708522643317\n\t Accuracy : 0.8982222222222223\n\n\ndiabetes_model version: 6\n\t Training context : Pipeline\n\t AUC : 0.8857616919468306\n\t Accuracy : 0.9011111111111111\n\n\ndiabetes_model version: 5\n\t Training context : Compute cluster\n\t AUC : 0.8844313976009577\n\t Accuracy : 0.8997777777777778\n\n\ndiabetes_model version: 4\n\t Training context : File dataset\n\t AUC : 0.8568517900798176\n\t Accuracy : 0.7891111111111111\n\n\ndiabetes_model version: 3\n\t Training context : Tabular dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\ndiabetes_model version: 2\n\t Training context : Parameterized script\n\t AUC : 0.8484377332205582\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 1\n\t Training context : Script\n\t AUC : 0.8483441962286681\n\t Accuracy : 0.774\n\n\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241483577
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['diabetes-model']\r\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes-model version 7\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241487553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create compute"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"compute-cluster-ds3-v2\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2', max_nodes=2)\r\n",
        "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        inference_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241490769
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a pipeline for batch inferencing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "# Create a folder for the experiment files\r\n",
        "experiment_folder = 'diabetes-batch-pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes-batch-pipeline\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241494137
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the batch inferencing script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_diabetes.py\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from azureml.core import Model\r\n",
        "import joblib\r\n",
        "\r\n",
        "\r\n",
        "def init():\r\n",
        "    # Runs when the pipeline step is initialized\r\n",
        "    global model\r\n",
        "\r\n",
        "    # load the model\r\n",
        "    model_path = Model.get_model_path('diabetes_model')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "    # This runs for each batch\r\n",
        "    resultList = []\r\n",
        "\r\n",
        "    # process each file in the batch\r\n",
        "    for f in mini_batch:\r\n",
        "        # Read the comma-delimited data into an array\r\n",
        "        data = np.genfromtxt(f, delimiter=',')\r\n",
        "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\r\n",
        "        prediction = model.predict(data.reshape(1, -1))\r\n",
        "        # Append prediction to results\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting diabetes-batch-pipeline/batch_diabetes.py\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a conda environment for the pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/diabetes_batch_environment.yml\r\n",
        "name: diabetes-batch-environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a run context that includes the conda environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# Create an Environment for the experiment\r\n",
        "batch_env = Environment.from_conda_specification(\"diabetes-batch-experiment_env\", experiment_folder + \"/diabetes_batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Configuration ready.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241511667
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the batch inferencing pipeline\r\n",
        "You're going to use a pipeline to run the batch prediction script, generate predictions from the input data, and save the results as a text file in the output folder. To do this, you can use a ParallelRunStep, which enables the batch data to be processed in parallel and the results collated in a single output file named parallel_run_step.txt."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory=experiment_folder,\r\n",
        "    entry_script=\"batch_diabetes.py\",\r\n",
        "    mini_batch_size=\"5\",\r\n",
        "    error_threshold=10,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    environment=batch_env,\r\n",
        "    compute_target=inference_cluster,\r\n",
        "    node_count=2)\r\n",
        "\r\n",
        "parallelrun_step = ParallelRunStep(\r\n",
        "    name='batch-score-diabetes',\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\r\n",
        "    output=output_dir,\r\n",
        "    arguments=[],\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241543856
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\r\n",
        "pipeline_run = Experiment(ws, 'diabetes-batch').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step batch-score-diabetes [a29e44ca][cc23a2a6-62bf-4bdc-ae99-bc14aaeb6d00], (This step is eligible to reuse a previous run's output)\nSubmitted PipelineRun ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2?wsid=/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourcegroups/rg-ml-test/workspaces/mlw-test&tid=67119780-27b3-4331-813a-0b239d67524a\nPipelineRunId: ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2?wsid=/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourcegroups/rg-ml-test/workspaces/mlw-test&tid=67119780-27b3-4331-813a-0b239d67524a\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2', 'status': 'Completed', 'startTimeUtc': '2023-02-01T08:52:32.509157Z', 'endTimeUtc': '2023-02-01T08:52:33.650184Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-01T08:52:32.869492+00:00\",\"EndTime\":\"2023-02-01T08:52:33.5633523+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlwtest6758284746.blob.core.windows.net/azureml/ExperimentRun/dcid.ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=1Ze%2B38AFjSX39x97NFB7v1bnJxusbqj4OgeE6p%2FQkgM%3D&skoid=48ea82e0-b5e8-4f07-99d1-2e857d3d1322&sktid=67119780-27b3-4331-813a-0b239d67524a&skt=2023-02-01T08%3A09%3A20Z&ske=2023-02-02T16%3A19%3A20Z&sks=b&skv=2019-07-07&st=2023-02-01T08%3A42%3A34Z&se=2023-02-01T16%3A52%3A34Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlwtest6758284746.blob.core.windows.net/azureml/ExperimentRun/dcid.ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ht%2FrTbb5tTY%2BeRGkG1cthJnoJDS1PbNVhn6ZXcMoHuM%3D&skoid=48ea82e0-b5e8-4f07-99d1-2e857d3d1322&sktid=67119780-27b3-4331-813a-0b239d67524a&skt=2023-02-01T08%3A09%3A20Z&ske=2023-02-02T16%3A19%3A20Z&sks=b&skv=2019-07-07&st=2023-02-01T08%3A42%3A34Z&se=2023-02-01T16%3A52%3A34Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlwtest6758284746.blob.core.windows.net/azureml/ExperimentRun/dcid.ccf6d2a2-02c4-4f01-9823-ed2eaaf37cb2/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=HqTtOsPnbE2bylH%2Bos4s8TUM%2BOgHLntFl88qA6f%2FmaE%3D&skoid=48ea82e0-b5e8-4f07-99d1-2e857d3d1322&sktid=67119780-27b3-4331-813a-0b239d67524a&skt=2023-02-01T08%3A09%3A20Z&ske=2023-02-02T16%3A19%3A20Z&sks=b&skv=2019-07-07&st=2023-02-01T08%3A42%3A34Z&se=2023-02-01T16%3A52%3A34Z&sp=r'}, 'submittedBy': 'Jon-Paul Boyd'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241553588
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve the batch inference results\r\n",
        "When the pipeline has finished running, the resulting predictions will have been saved in the outputs of the experiment associated with the first (and only) step in the pipeline. You can retrieve it as follows:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('diabetes-batch-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='diabetes-batch-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('diabetes-batch-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "      File  Prediction\n0   11.csv           0\n1   12.csv           0\n2   13.csv           1\n3   14.csv           0\n4   15.csv           0\n5   16.csv           0\n6   17.csv           0\n7   18.csv           1\n8   19.csv           1\n9    2.csv           0\n10  20.csv           0\n11  21.csv           0\n12  22.csv           0\n13  23.csv           0\n14  24.csv           1\n15  25.csv           0\n16  26.csv           1\n17  27.csv           0\n18  28.csv           0\n19  29.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>21.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>24.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>25.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>26.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>27.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>28.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>29.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241613597
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Publish the Pipeline and use its REST Interface\r\n",
        "Now that you have a working pipeline for batch inferencing, you can publish it and use a REST endpoint to run it from an application."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\r\n",
        "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\r\n",
        "\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Pipeline(Name: diabetes-batch-pipeline,\nId: fd36a80f-9fbb-45a6-a005-62dbd6c9d04c,\nStatus: Active,\nEndpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourceGroups/rg-ml-test/providers/Microsoft.MachineLearningServices/workspaces/mlw-test/PipelineRuns/PipelineSubmit/fd36a80f-9fbb-45a6-a005-62dbd6c9d04c)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/fd36a80f-9fbb-45a6-a005-62dbd6c9d04c?wsid=/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourcegroups/rg-ml-test/workspaces/mlw-test\" target=\"_blank\" rel=\"noopener\">fd36a80f-9fbb-45a6-a005-62dbd6c9d04c</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourceGroups/rg-ml-test/providers/Microsoft.MachineLearningServices/workspaces/mlw-test/PipelineRuns/PipelineSubmit/fd36a80f-9fbb-45a6-a005-62dbd6c9d04c\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241621616
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the published pipeline has an endpoint, which you can see in the Azure portal. You can also find it as a property of the published pipeline object:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "print(rest_endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourceGroups/rg-ml-test/providers/Microsoft.MachineLearningServices/workspaces/mlw-test/PipelineRuns/PipelineSubmit/fd36a80f-9fbb-45a6-a005-62dbd6c9d04c\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241651242
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. To test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:\r\n",
        "> **Note**: A real application would require a service principal with which to be authenticated."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "\r\n",
        "interactive_auth = InteractiveLoginAuthentication()\r\n",
        "auth_header = interactive_auth.get_authentication_header()\r\n",
        "print('Authentication header ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Authentication header ready.\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241643803
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "\r\n",
        "rest_endpoint = published_pipeline.endpoint\r\n",
        "response = requests.post(rest_endpoint, \r\n",
        "                         headers=auth_header, \r\n",
        "                         json={\"ExperimentName\": \"diabetes-batch\"})\r\n",
        "run_id = response.json()[\"Id\"]\r\n",
        "run_id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'374f5f94-c5b2-401d-b047-8d148eab317c'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241695694
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have the run ID, we can use the RunDetails widget to view the experiment as it runs:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "published_pipeline_run = PipelineRun(ws.experiments['diabetes-batch'], run_id)\r\n",
        "\r\n",
        "# Block until the run completes\r\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 374f5f94-c5b2-401d-b047-8d148eab317c\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/374f5f94-c5b2-401d-b047-8d148eab317c?wsid=/subscriptions/fad2758e-cc1a-4f45-8323-6b466001d50a/resourcegroups/rg-ml-test/workspaces/mlw-test&tid=67119780-27b3-4331-813a-0b239d67524a\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '374f5f94-c5b2-401d-b047-8d148eab317c', 'status': 'Completed', 'startTimeUtc': '2023-02-01T08:54:58.54624Z', 'endTimeUtc': '2023-02-01T08:54:59.68383Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineid': 'fd36a80f-9fbb-45a6-a005-62dbd6c9d04c', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-02-01T08:54:58.8475964+00:00\",\"EndTime\":\"2023-02-01T08:54:59.5865768+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlwtest6758284746.blob.core.windows.net/azureml/ExperimentRun/dcid.374f5f94-c5b2-401d-b047-8d148eab317c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=a2VofLI4i5Uc8wcKszJrcXeQYyXykXkTOpembbKN0Gk%3D&skoid=48ea82e0-b5e8-4f07-99d1-2e857d3d1322&sktid=67119780-27b3-4331-813a-0b239d67524a&skt=2023-02-01T08%3A09%3A20Z&ske=2023-02-02T16%3A19%3A20Z&sks=b&skv=2019-07-07&st=2023-02-01T08%3A45%3A13Z&se=2023-02-01T16%3A55%3A13Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlwtest6758284746.blob.core.windows.net/azureml/ExperimentRun/dcid.374f5f94-c5b2-401d-b047-8d148eab317c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=z9DOQA4EQ93WGL24b2LhYVlG1WK3dhTFt%2BDFt24IEA4%3D&skoid=48ea82e0-b5e8-4f07-99d1-2e857d3d1322&sktid=67119780-27b3-4331-813a-0b239d67524a&skt=2023-02-01T08%3A09%3A20Z&ske=2023-02-02T16%3A19%3A20Z&sks=b&skv=2019-07-07&st=2023-02-01T08%3A45%3A13Z&se=2023-02-01T16%3A55%3A13Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlwtest6758284746.blob.core.windows.net/azureml/ExperimentRun/dcid.374f5f94-c5b2-401d-b047-8d148eab317c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=4TQgzOjKlv1Th8m3aAmw2%2FTArnnO7hMUAqIDeGLDh50%3D&skoid=48ea82e0-b5e8-4f07-99d1-2e857d3d1322&sktid=67119780-27b3-4331-813a-0b239d67524a&skt=2023-02-01T08%3A09%3A20Z&ske=2023-02-02T16%3A19%3A20Z&sks=b&skv=2019-07-07&st=2023-02-01T08%3A45%3A13Z&se=2023-02-01T16%3A55%3A13Z&sp=r'}, 'submittedBy': 'Jon-Paul Boyd'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241897594
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait for the pipeline run to complete, and then run the following cell to see the results.\r\n",
        "\r\n",
        "As before, the results are in the output of the first pipeline step:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('diabetes-batch-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='diabetes-batch-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('diabetes-batch-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "      File  Prediction\n0   11.csv           0\n1   12.csv           0\n2   13.csv           1\n3   14.csv           0\n4   15.csv           0\n5   16.csv           0\n6   17.csv           0\n7   18.csv           1\n8   19.csv           1\n9    2.csv           0\n10  20.csv           0\n11  21.csv           0\n12  22.csv           0\n13  23.csv           0\n14  24.csv           1\n15  25.csv           0\n16  26.csv           1\n17  27.csv           0\n18  28.csv           0\n19  29.csv           0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>16.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>19.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>21.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>22.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>23.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>24.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>25.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>26.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>27.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>28.csv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>29.csv</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675241908966
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}