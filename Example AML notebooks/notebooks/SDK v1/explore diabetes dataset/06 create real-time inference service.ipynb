{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to the workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.48.0 to work with mlw-test\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190442093
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's take a look at models registered in the workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes-model version: 7\n\t Algorithm : Decision Tree Classifier\n\t Training context : Pipeline\n\t AUC : 0.8832546157718848\n\t Accuracy : 0.898\n\n\ndiabetes-model version: 6\n\t Algorithm : Logistic Regression\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 5\n\t Algorithm : Decision Tree Classifier\n\t Training context : Pipeline\n\t AUC : 0.88375696004516\n\t Accuracy : 0.8986666666666666\n\n\ndiabetes-model version: 4\n\t Algorithm : Logistic Regression\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 3\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 2\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes-model version: 1\n\t Training context : Tabular diabetes data asset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\t Regularization Rate : 0.1\n\n\ndiabetes_model version: 10\n\t Training context : File dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\nnyc-taxi-fare version: 1\n\t Type : GradientBoostingRegressor\n\t Run ID : a467b104-6d83-492e-8b51-e27ef3274918\n\t Metrics : {'rmse': 4.201611563528527, 'mae': 2.1113181246358903, 'R2 score': 0.8145380981078642}\n\n\ndiabetes_model version: 9\n\t Training context : Inline Training\n\t AUC : 0.8753520075625654\n\t Accuracy : 0.888\n\n\ndiabetes_model version: 8\n\t Training context : Pipeline\n\t AUC : 0.881942902191734\n\t Accuracy : 0.8975555555555556\n\n\ndiabetes_model version: 7\n\t Training context : Pipeline\n\t AUC : 0.8827708522643317\n\t Accuracy : 0.8982222222222223\n\n\ndiabetes_model version: 6\n\t Training context : Pipeline\n\t AUC : 0.8857616919468306\n\t Accuracy : 0.9011111111111111\n\n\ndiabetes_model version: 5\n\t Training context : Compute cluster\n\t AUC : 0.8844313976009577\n\t Accuracy : 0.8997777777777778\n\n\ndiabetes_model version: 4\n\t Training context : File dataset\n\t AUC : 0.8568517900798176\n\t Accuracy : 0.7891111111111111\n\n\ndiabetes_model version: 3\n\t Training context : Tabular dataset\n\t AUC : 0.8568650620553335\n\t Accuracy : 0.7893333333333333\n\n\ndiabetes_model version: 2\n\t Training context : Parameterized script\n\t AUC : 0.8484377332205582\n\t Accuracy : 0.774\n\n\ndiabetes_model version: 1\n\t Training context : Script\n\t AUC : 0.8483441962286681\n\t Accuracy : 0.774\n\n\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190445432
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ws.models['diabetes-model']\r\n",
        "print(model.name, 'version', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes-model version 7\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190445711
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As we are going to create a web service to host this model, this will require some code and configuration files; so let's create a folder for those."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# Create a folder for the deployment files\r\n",
        "deployment_folder = './diabetes-service'\r\n",
        "os.makedirs(deployment_folder, exist_ok=True)\r\n",
        "print(deployment_folder, 'folder created.')\r\n",
        "\r\n",
        "# Set path for scoring script\r\n",
        "script_file = 'score_diabetes.py'\r\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "./diabetes-service folder created.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190445832
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an entry script (often called a scoring script) that will be deployed to the web service.\r\n",
        "\r\n",
        "The script consists of two functions:\r\n",
        "\r\n",
        "**init:** This function is called when the service is initialized, and is generally used to load the model. Note that the scoring script uses the AZUREML_MODEL_DIR environment variable to determine the folder where the model is stored.\r\n",
        "\r\n",
        "**run:** This function is called each time a client application submits new data, and is generally used to inference predictions from the model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_path\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "# Called when the service is loaded\r\n",
        "def init():\r\n",
        "    global model\r\n",
        "    # Get the path to the deployed model file and load it\r\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "# Called when a request is received\r\n",
        "def run(raw_data):\r\n",
        "    # Get the input data as a numpy array\r\n",
        "    data = np.array(json.loads(raw_data)['data'])\r\n",
        "    # Get a prediction from the model\r\n",
        "    predictions = model.predict(data)\r\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\r\n",
        "    classnames = ['not-diabetic', 'diabetic']\r\n",
        "    predicted_classes = []\r\n",
        "    for prediction in predictions:\r\n",
        "        predicted_classes.append(classnames[prediction])\r\n",
        "    # Return the predictions as JSON\r\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./diabetes-service/score_diabetes.py\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires scikit-learn and some Azure Machine Learning specific packages that are used by the scoring web service, so we'll create an environment that included these. Then we'll add that environment to an inference configuration along with the scoring script, and define a deployment configuration for the container in which the environment and script will be hosted.\r\n",
        "\r\n",
        "We can then deploy the model as a service based on these configurations.\r\n",
        "\r\n",
        "More Information: For more details about model deployment, and options for target execution environments, see the documentation.\r\n",
        "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of Healthy."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_name = \"diabetes-service\""
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190446296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "# Configure the scoring environment\r\n",
        "service_env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\r\n",
        "service_env.inferencing_stack_version=\"latest\""
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190446461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_config = InferenceConfig(source_directory=deployment_folder,\r\n",
        "                                   entry_script=script_file,\r\n",
        "                                   environment=service_env)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190446597
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deploy_to_container_instance = True"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190446722
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy to an Azure Container Instance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if deploy_to_container_instance:\r\n",
        "    print('Deploying model as Azure Container Image...')\r\n",
        "    deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\r\n",
        "    service.wait_for_deployment(True)\r\n",
        "else:\r\n",
        "    print('Deploying model as local web service...')\r\n",
        "    deployment_config = LocalWebservice.deploy_configuration(port=8890)\r\n",
        "    service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\r\n",
        "\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Deploying model as Azure Container Image...\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-01-31 18:40:49+00:00 Creating Container Registry if not exists.\n2023-01-31 18:40:49+00:00 Registering the environment.\n2023-01-31 18:40:50+00:00 Use the existing image.\n2023-01-31 18:40:50+00:00 Generating deployment configuration.\n2023-01-31 18:40:51+00:00 Submitting deployment to compute.\n2023-01-31 18:40:57+00:00 Checking the status of deployment diabetes-service..\n2023-01-31 18:43:12+00:00 Checking the status of inference endpoint diabetes-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190663231
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Or deploy to a local web service for troubleshooting"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())\r\n",
        "\r\n",
        "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\r\n",
        "#service.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2023-01-31T18:43:04,949912639+00:00 - gunicorn/run \n2023-01-31T18:43:04,954112033+00:00 | gunicorn/run | \n2023-01-31T18:43:04,960681824+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:04,962516622+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-01-31T18:43:04,968928413+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:04,970488811+00:00 | gunicorn/run | \n2023-01-31T18:43:04,984405892+00:00 | gunicorn/run | \n2023-01-31T18:43:05,003823566+00:00 | gunicorn/run | AzureML image information: sklearn-0.24.1-ubuntu18.04-py37-cpu-inference:20221024.v1\n2023-01-31T18:43:05,005948463+00:00 | gunicorn/run | \n2023-01-31T18:43:05,015695150+00:00 | gunicorn/run | \n2023-01-31T18:43:05,017593447+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/amlenv/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-01-31T18:43:05,025597936+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-01-31T18:43:05,027361334+00:00 | gunicorn/run | \n2023-01-31T18:43:05,035210323+00:00 - nginx/run \n2023-01-31T18:43:15,734740956+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\nbase                  *  /opt/miniconda\namlenv                   /opt/miniconda/envs/amlenv\n\n2023-01-31T18:43:17,055938187+00:00 | gunicorn/run | \n2023-01-31T18:43:17,061795435+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nazure-core==1.26.0\nazure-identity==1.11.0\nazureml-inference-server-http==0.7.6\ncachetools==5.2.0\ncertifi==2022.9.24\ncffi==1.15.1\ncharset-normalizer==2.1.1\nclick==8.1.3\ncryptography==38.0.1\nFlask==2.1.3\nFlask-Cors==3.0.10\ngoogle-api-core==2.10.2\ngoogle-auth==2.13.0\ngoogleapis-common-protos==1.56.4\ngunicorn==20.1.0\nidna==3.4\nimportlib-metadata==5.0.0\ninference-schema==1.4.2.1\nitsdangerous==2.1.2\nJinja2==3.1.2\njoblib==1.2.0\nMarkupSafe==2.1.1\nmsal==1.20.0\nmsal-extensions==1.0.0\nnumpy==1.21.6\nopencensus==0.11.0\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.7\npandas==1.1.5\nportalocker==2.6.0\nprotobuf==4.21.8\npsutil==5.9.3\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.21\nPyJWT==2.6.0\npython-dateutil==2.8.2\npytz==2022.5\nrequests==2.28.1\nrsa==4.9\nscikit-learn==0.24.1\nscipy==1.7.3\nsix==1.16.0\nthreadpoolctl==3.1.0\ntyping-extensions==4.4.0\nurllib3==1.26.12\nWerkzeug==2.2.2\nwrapt==1.12.1\nzipp==3.10.0\n\n2023-01-31T18:43:26,984603667+00:00 | gunicorn/run | \n2023-01-31T18:43:26,993748029+00:00 | gunicorn/run | Entry script directory: /var/azureml-app\n2023-01-31T18:43:26,998647916+00:00 | gunicorn/run | \n2023-01-31T18:43:27,000375247+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:27,006081448+00:00 | gunicorn/run | Dynamic Python Package Installation\n2023-01-31T18:43:27,007844780+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:27,015534316+00:00 | gunicorn/run | \n2023-01-31T18:43:27,017301948+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n2023-01-31T18:43:27,024774980+00:00 | gunicorn/run | \n2023-01-31T18:43:27,031437499+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:27,033486935+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-01-31T18:43:27,039976250+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:27,046019358+00:00 | gunicorn/run | \n2023-01-31T18:43:30,691548738+00:00 | gunicorn/run | \n2023-01-31T18:43:30,693800097+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:30,698880575+00:00 | gunicorn/run | AzureML Inference Server\n2023-01-31T18:43:30,701699797+00:00 | gunicorn/run | ###############################################\n2023-01-31T18:43:30,706819166+00:00 | gunicorn/run | \n2023-01-31T18:43:30,708728806+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n\nAzure ML Inferencing HTTP server v0.7.6\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/main.py\nModel Directory: /var/azureml-app/azureml-models/diabetes-model/7\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/0.7.6\nCORS for the specified origins: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\nStarting gunicorn 20.1.0\nListening at: http://0.0.0.0:31311 (76)\nUsing worker: sync\nBooting worker with pid: 187\nInitializing logger\n2023-01-31 18:43:55,366 | root | INFO | Starting up app insights client\nlogging socket not found. logging not available.\nlogging socket not found. logging not available.\n2023-01-31 18:43:55,368 | root | INFO | Starting up app insight hooks\n2023-01-31 18:43:57,981 | root | INFO | Found driver script at /var/azureml-app/main.py and the score script at /var/azureml-app/diabetes-service/score_diabetes.py\n2023-01-31 18:43:57,982 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\n2023-01-31 18:43:57,982 | root | INFO | Invoking user's init function\n00000000-0000-0000-0000-000000000000,/opt/miniconda/envs/amlenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n  UserWarning)\n2023-01-31 18:44:09,156 | root | INFO | Users's init has completed successfully\n2023-01-31 18:44:09,166 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n2023-01-31 18:44:09,166 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n2023-01-31 18:44:09,170 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n2023-01-31 18:44:20,764 | root | INFO | 200\n127.0.0.1 - - [31/Jan/2023:18:44:20 +0000] \"GET /swagger.json HTTP/1.0\" 200 2265 \"-\" \"Go-http-client/1.1\"\n2023-01-31 18:44:23,600 | root | INFO | 200\n127.0.0.1 - - [31/Jan/2023:18:44:23 +0000] \"GET /swagger.json HTTP/1.0\" 200 2265 \"-\" \"Go-http-client/1.1\"\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190666210
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for webservice_name in ws.webservices:\r\n",
        "    print(webservice_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "diabetes-service\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190666478
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\r\n",
        "print ('Patient: {}'.format(x_new[0]))\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "\r\n",
        "# Get the predicted class - it'll be the first (and only) one.\r\n",
        "predicted_classes = json.loads(predictions)\r\n",
        "print(predicted_classes[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\ndiabetic\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190666607
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "# This time our input is an array of two feature arrays\r\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\r\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\r\n",
        "\r\n",
        "# Convert the array or arrays to a serializable list in a JSON document\r\n",
        "input_json = json.dumps({\"data\": x_new})\r\n",
        "\r\n",
        "# Call the web service, passing the input data\r\n",
        "predictions = service.run(input_data = input_json)\r\n",
        "\r\n",
        "# Get the predicted classes.\r\n",
        "predicted_classes = json.loads(predictions)\r\n",
        "   \r\n",
        "for i in range(len(x_new)):\r\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\nPatient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] diabetic\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190666733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = service.scoring_uri\r\n",
        "print(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "http://4bd72f7e-dd71-452c-88ce-89966b25664f.westeurope.azurecontainer.io/score\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190666867
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#service.delete()\r\n",
        "#print ('Service deleted.')"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675190666995
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK V2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}